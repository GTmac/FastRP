{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import csv\n",
    "import datetime\n",
    "import json\n",
    "import matplotlib\n",
    "import time\n",
    "import logging\n",
    "import sys\n",
    "import sqlite3\n",
    "import os\n",
    "import random\n",
    "\n",
    "import gensim\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from scipy.io import loadmat, savemat\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_client import find_connection_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_connection_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.style.use('ggplot')\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ls /mnt/store1/hcchen/www-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/mnt/store1/hcchen/www-network/'\n",
    "rank_fname = 'ranks.txt'\n",
    "edges_fname = 'edges.txt'\n",
    "vertices_fname = 'vertices.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get node to ID mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "node_to_id = {}\n",
    "with open(os.path.join(data_dir, vertices_fname), 'r') as fp:\n",
    "    reader = csv.reader(fp, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        node_to_id[row[1]] = row[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter based on harmony centrality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "node_set = set()\n",
    "\n",
    "with open(os.path.join(data_dir, rank_fname)) as fp:\n",
    "    reader = csv.DictReader(fp, delimiter='\\t')\n",
    "    for i, row in enumerate(reader):\n",
    "        if i >= K:\n",
    "            break\n",
    "        node_set.add(node_to_id[row['#host_rev']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This mapping is huge, so we are going to only take the relevant part later (i.e. for top-K nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time node_to_id = {node: id for node, id in node_to_id.items() if id in node_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time id_to_node = {id: node for node, id in node_to_id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to choose the subgraph with only the top-K most important nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, rank_fname), 'r') as fp:\n",
    "    for i, row in enumerate(fp):\n",
    "        print (row, end=\"\")\n",
    "        if i >= 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the subgraph consisting of top-K nodes: (this is slow, taking ~30min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "with open(os.path.join(data_dir, edges_fname)) as fp:\n",
    "    for line in tqdm(fp, total=2504610000):\n",
    "        row = line.strip().split('\\t')\n",
    "        if row[0] in node_set and row[1] in node_set\n",
    "        \n",
    "            # print (id_to_node[row[0]], id_to_node[row[1]])\n",
    "            G.add_edge(row[0], row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_adjlist(G, open('network-200k.adjlist', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_adjlist(G, open('network-10k.adjlist', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: we need additional post-processing to remove some unnecessary content in the adj list file!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it seems that even without post-processing our algorithm is working well. Weird :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepWalk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the following command in terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepwalk --format adjlist --input network-10k.adjlist \\\n",
    "--max-memory-data-size 0 --number-walks 80 --representation-size 128 --walk-length 40 --window-size 10 \\\n",
    "--workers 38 --output www-network/10k.embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN of Representative websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are representative website? We define a list of them here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representative_sites = ['com.facebook',\n",
    "                        'com.twitter',\n",
    "                        'com.google',\n",
    "                        'com.linkedin',\n",
    "                        'com.instagram',\n",
    "                        'com.amazon',\n",
    "                        'com.google.mail',\n",
    "                        'com.nytimes',\n",
    "                        'org.acm',\n",
    "                        'gov.treasury',\n",
    "                        'com.baidu',\n",
    "                        'com.dell',\n",
    "                        'com.github'\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the 200K graph from file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_adjlist('/mnt/store1/hcchen/ws/large-network-embeddings/www-network/network-200k.adjlist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to map the nodes to range of 0 -> N - 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_to_matid = {node: index for index, node in enumerate(G.nodes())}\n",
    "matid_to_node = {index: node for index, node in enumerate(G.nodes())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a sparse matrix from the adj list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rows, cols = [], []\n",
    "\n",
    "for node in G.nodes():\n",
    "    u = node_to_matid[node]\n",
    "    for adj_node in G[node]:\n",
    "        v = node_to_matid[adj_node]\n",
    "        rows.append(u)\n",
    "        cols.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = csr_matrix( ([1.0] * len(rows), (rows, cols)), shape=(G.number_of_nodes(), G.number_of_nodes()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat('network-200k.mat', {'A': m})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run RandNE in both MATLAB and Python (my own implementation!) to get the embedding vectors. We load the embeddings here; note that there are two versions of the embeddings, one built from the adjacency matrix and the other one built from the transition matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /home/hcchen/ws/large-network-embeddings/www-network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run my RandNE implementation on trans matrix: ``python3 src/randne.py --matfile-variable-name A --input /home/hcchen/ws/large-network-embeddings/www-network/network-200k.mat --output /home/hcchen/ws/large-network-embeddings/www-network/randne-py-trans-www-200k.mat --use-trans-matrix -q 3 -d 128 --weights 1 100 1000``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run my RandNE implementation on adj matrix: ``python3 src/randne.py --matfile-variable-name A --input /home/hcchen/ws/large-network-embeddings/www-network/network-200k.mat --output /home/hcchen/ws/large-network-embeddings/www-network/randne-py-adj-www-200k.mat -q 2 -d 128 --weights 1 0.01``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_randne_py_trans_200k = loadmat('www-network/randne-py-trans-www-200k.mat')['emb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_randne_py_adj_200k = loadmat('www-network/randne-py-adj-www-200k.mat')['emb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_randne_trans_200k = loadmat('www-network/randne-trans-www-200k.mat')['U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_randne_adj_200k = loadmat('www-network/randne-adj-www-200k.mat')['U_adj']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function for querying mosy similar sites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_sites_randne(emb, site, k=10):\n",
    "    site_id = node_to_matid[node_to_id[site]]\n",
    "    all_sim = cosine_similarity(np.expand_dims(emb[site_id], axis=0), emb)\n",
    "    neighbors = sorted([(sim, index) for index, sim in enumerate(all_sim[0])], key=lambda x:-x[0])[1:k+1]\n",
    "    neighbor_names = [id_to_node[matid_to_node[index]] for (_, index) in neighbors]\n",
    "    \n",
    "    return neighbor_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of cosine similarity is.. a bit weird?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(randne_sim0[0], bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepWalk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the DeepWalk embeddings we got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_200k_dw = gensim.models.KeyedVectors.load_word2vec_format('www-network/200k.embeddings', binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification, we need to index the nodes from 0 to N - 1 consecutively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_to_matid['283881577']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matid_to_node[1012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_200k_dw_reindexed = np.asarray([emb_200k_dw.get_vector(matid_to_node[matid]) for matid in range(G.number_of_nodes())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the re-indexed embeddings to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat('www-network/deepwalk-www-200k.mat', {'emb': emb_200k_dw_reindexed})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_sites(emb, site):\n",
    "    site_id = node_to_id[site]\n",
    "    neighbors = emb.most_similar(site_id)\n",
    "    # print (neighbors)\n",
    "    # id, similarity\n",
    "    return [id_to_node[id] for id, _ in neighbors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in representative_sites:\n",
    "    print ('Site chosen:', site)\n",
    "    print ('Nearest neighbors: ')\n",
    "    print (most_similar_sites(emb_200k_dw, site), '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN: RandNE vs DeepWalk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful resource for finding top websites based on category: https://www.similarweb.com/top-websites/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuanced_sites = [\n",
    "#     'com.archdaily',\n",
    "#     'com.premierleague',\n",
    "#     'com.nba',\n",
    "#     'com.audible',\n",
    "#     'com.mountainproject',\n",
    "#     'org.wikipedia',\n",
    "#     'org.archive',\n",
    "#     'org.sigir',\n",
    "#     'com.delta',\n",
    "#     'com.ford',\n",
    "#     'com.citi',\n",
    "#     'com.weather',\n",
    "#     'com.imdb',\n",
    "#     'com.chase'\n",
    "    'edu.stonybrook',\n",
    "    'com.baidu',\n",
    "    'com.chase',\n",
    "    'org.wikipedia'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_site = lambda x: '.'.join(x.split('.')[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for site in nuanced_sites:\n",
    "    print ('Site chosen:', site)\n",
    "    print ('Nearest neighbors from RandNE Adj: ')\n",
    "    print (list(map(reverse_site, most_similar_sites_randne(emb_randne_py_adj_200k, site))), '\\n')\n",
    "\n",
    "    print ('Nearest neighbors from RandNE Trans: ')\n",
    "    print (list(map(reverse_site, most_similar_sites_randne(emb_randne_py_trans_200k, site))) )\n",
    "    \n",
    "    print ('\\n**************************\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in nuanced_sites:\n",
    "    print ('Site chosen:', site)\n",
    "    print ('Nearest neighbors from DeepWalk: ')\n",
    "    print (list(map(reverse_site, most_similar_sites(emb_200k_dw, site))), '\\n')\n",
    "    \n",
    "    print ('Nearest neighbors from RandNE Adj: ')\n",
    "    print (list(map(reverse_site, most_similar_sites_randne(emb_randne_adj_200k, site))), '\\n')\n",
    "\n",
    "#     print ('Nearest neighbors from RandNE Trans: ')\n",
    "#     print (list(map(reverse_site, most_similar_sites_randne(emb_randne_trans_200k, site))) )\n",
    "    \n",
    "    print ('\\n**************************\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in nuanced_sites:\n",
    "    print ('Site chosen:', site)\n",
    "    print ('Nearest neighbors from DeepWalk: ')\n",
    "    print (list(map(reverse_site, most_similar_sites(emb_200k_dw, site))), '\\n')\n",
    "    \n",
    "    print ('Nearest neighbors from RandNE Adj: ')\n",
    "    print (list(map(reverse_site, most_similar_sites_randne(emb_randne_adj_200k, site))), '\\n')\n",
    "\n",
    "#     print ('Nearest neighbors from RandNE Trans: ')\n",
    "#     print (list(map(reverse_site, most_similar_sites_randne(emb_randne_trans_200k, site))) )\n",
    "    \n",
    "    print ('\\n**************************\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we take the domain extensions as labels of nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_label = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_to_label = {node: id_to_node[node].split('.')[0] for node in node_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = Counter(node_to_label.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of (the most common) labels among top 10k websites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_label_counts = sorted(label_counts.items(), key=lambda x: -x[1])[:K_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_labels, top_counts = zip(*top_label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "df = pd.DataFrame.from_dict({'label': top_labels, 'count': top_counts})\n",
    "df = df.set_index('label')\n",
    "_ = df.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want these labels to have consecutive integer IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id = {}\n",
    "for index, label in enumerate(top_labels):\n",
    "    label_to_id[label] = index\n",
    "label_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_labels_with_dot = list(map(lambda x: '.' + x, top_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~For classification, let's use these top 20 labels, and ignore the other examples. We also ensure the number of examples from each class is the same:~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly sample 1,000 nodes from each class, and ignore the websites which do not belong to the top K classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_sample = 1000\n",
    "sampled_nodes = [[] for _ in range(K_label)]\n",
    "for i in range(N):\n",
    "    if node_to_label[matid_to_node[i]] in label_to_id:\n",
    "        sampled_nodes[label_to_id[node_to_label[matid_to_node[i]]]].append(i)\n",
    "\n",
    "sampled_nodes = [sample for elements in sampled_nodes for sample in random.sample(elements, K_sample)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the adjacency matrix + label matrix to a single .mat file (we are re-using the sparse matrix from the RandNE chapter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(sampled_nodes)\n",
    "rows = list(range(N))\n",
    "cols = [label_to_id[node_to_label[matid_to_node[node]]] for node in sampled_nodes]\n",
    "label_mat = csr_matrix( ( ([1.0] * N), (rows, cols) ), shape=(N, K_label) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(label_mat, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat('www-network/www-200k-classification.mat', {'group': label_mat})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we need to pick embeddings just for these sampled nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For DeepWalk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_200k_dw_classification = \\\n",
    "    np.asarray([emb_200k_dw.get_vector(matid_to_node[matid]) for matid in sampled_nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat('www-network/deepwalk-www-200k-classification.mat', {'emb': emb_200k_dw_classification})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For RandNE MATLAB Adj:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_randne_adj_200k_classification = emb_randne_adj_200k[sampled_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat('www-network/randne-adj-www-200k-classification.mat', {'emb': emb_randne_adj_200k_classification})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For RandNE Python Adj:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_randne_py_adj_200k_classification = emb_randne_py_adj_200k[sampled_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat('www-network/randne-py-adj-www-200k-classification.mat', {'emb': emb_randne_py_adj_200k_classification})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For RandNE Python Trans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_randne_py_trans_200k_classification = emb_randne_py_trans_200k[sampled_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat('www-network/randne-py-trans-www-200k-classification.mat', {'emb': emb_randne_py_trans_200k_classification})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "prefix = 'result/www'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "order_range = 2\n",
    "def objective(trial):\n",
    "\n",
    "    # Invoke suggest methods of a Trial object to generate hyperparameters.\n",
    "    weights = [trial.suggest_loguniform('weight' + str(order), 1.0, 64.0) for order in range(order_range)]\n",
    "    alpha = trial.suggest_uniform('alpha', -1.0, 1.0)\n",
    "    conf = {\n",
    "        'projection_method': 'sparse',\n",
    "        'input_matrix': 'trans',\n",
    "        'weights': [1.0, 1.0] + weights,\n",
    "        'normalization': True,\n",
    "        'dim': 128,\n",
    "        'alpha': alpha,\n",
    "        'C': 0.1\n",
    "    }\n",
    "    emb_filename = get_emb_filename(prefix, conf)\n",
    "    print (emb_filename)\n",
    "    # first check if this file already exists\n",
    "    path = Path(emb_filename)\n",
    "    if not path.is_file():\n",
    "        U = fastrp_wrapper(A, conf)\n",
    "        savemat(emb_filename, {'emb': U})\n",
    "    else:\n",
    "        print ('File %s already exists, skipped.' % emb_filename)\n",
    "    f1_scores = scoring(\n",
    "        [\n",
    "            \"--emb\", emb_filename,\n",
    "            \"--network\",\"example_graphs/blogcatalog.mat\",\n",
    "            \"--num-shuffles\", \"3\",\n",
    "            \"--debug\",\n",
    "            \"--C\", str(conf['C']),\n",
    "            \"--training-percents\", \"10\",\n",
    "        ]\n",
    "    )\n",
    "    # there should only be one entry here\n",
    "    return -f1_scores[0]['micro']\n",
    "\n",
    "study = optuna.create_study()  # Create a new study.\n",
    "study.optimize(objective, n_trials=100)  # Invoke optimization of the objective function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 10% training data we get: `Average score: {'micro': 0.7724027777777778, 'macro': 0.5314847218405359}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python scoring.py --emb ~/ws/large-network-embeddings/www-network/randne-adj-www-200k.mat \\\n",
    "--network ~/ws/large-network-embeddings/www-network/www-200k.mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get: `Average score: {'micro': 0.7302805555555556, 'macro': 0.36847663239140405}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python scoring.py --emb ~/ws/large-network-embeddings/www-network/randne-trans-www-200k.mat \\\n",
    "--network ~/ws/large-network-embeddings/www-network/www-200k.mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get: `Average score: {'micro': 0.7369333333333333, 'macro': 0.2991826875988267}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also would like to output the confusion matrix of the classification result. So we also train these models inline here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/hcchen/ws/large-network-embeddings')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat_dw = main(\n",
    "    [\"--emb\", \"/home/hcchen/ws/large-network-embeddings/www-network/deepwalk-www-200k-classification.mat\",\n",
    "      \"--network\",\"/home/hcchen/ws/large-network-embeddings/www-network/www-200k-classification.mat\",\n",
    "      \"--num-shuffles\", \"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat_randne_adj = main(\n",
    "    [\"--emb\", \"/home/hcchen/ws/large-network-embeddings/www-network/randne-adj-www-200k-classification.mat\",\n",
    "      \"--network\",\"/home/hcchen/ws/large-network-embeddings/www-network/www-200k-classification.mat\",\n",
    "      \"--num-shuffles\", \"1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two results below are based on my implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat_randne_py_adj = main(\n",
    "    [\"--emb\", \"/home/hcchen/ws/large-network-embeddings/www-network/randne-py-adj-www-200k-classification.mat\",\n",
    "      \"--network\",\"/home/hcchen/ws/large-network-embeddings/www-network/www-200k-classification.mat\",\n",
    "      \"--num-shuffles\", \"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat_randne_py_trans = main(\n",
    "    [\"--emb\", \"/home/hcchen/ws/large-network-embeddings/www-network/randne-py-trans-www-200k-classification.mat\",\n",
    "      \"--network\",\"/home/hcchen/ws/large-network-embeddings/www-network/www-200k-classification.mat\",\n",
    "      \"--num-shuffles\", \"1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(confusion_mat_dw)\n",
    "df['top-level domain'] = top_labels_with_dot\n",
    "df.set_index('top-level domain', inplace=True)\n",
    "df.columns = top_labels_with_dot\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.set(font_scale=1.6)\n",
    "sns.heatmap(df, cmap='Blues', fmt='g', annot=True,annot_kws={\"size\": 14},\n",
    "           vmin=0, vmax=1000) # anno font size\n",
    "plt.savefig('deepwalk-classification-mat.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(confusion_mat_randne_adj)\n",
    "df['top-level domain'] = top_labels_with_dot\n",
    "df.set_index('top-level domain', inplace=True)\n",
    "df.columns = top_labels_with_dot\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.set(font_scale=1.6)\n",
    "sns.heatmap(df, cmap='Blues', fmt='g', annot=True,annot_kws={\"size\": 14},\n",
    "           vmin=0, vmax=1000) # anno font size\n",
    "plt.savefig('randne-classification-mat.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another experiment is to see how well can both methods separate sites with different top-level domains in the embedding space. Let us still consider the same set of sites as in the classification experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_200k_dw_classification = loadmat('www-network/deepwalk-www-200k-classification.mat')['emb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = emb_200k_dw_classification.shape[0]\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For DeepWalk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "deepwalk_tsne = tsne.fit_transform(emb_200k_dw_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deepwalk_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_domains = set([0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k', 'lightpink', 'orange', 'purple']\n",
    "for label in range(K_label):\n",
    "    if label in filtered_domains:\n",
    "        continue\n",
    "    candidates = [i for i in range(N) if cols[i] == label]\n",
    "    plt.scatter(deepwalk_tsne[candidates, 0], deepwalk_tsne[candidates, 1],\n",
    "                s=40, c=colors[label], label=top_labels_with_dot[label])\n",
    "plt.legend()\n",
    "# plt.legend(bbox_to_anchor=(1., 0., 1., 1.), loc=1,\n",
    "#            ncol=1, mode=\"expand\", borderaxespad=0., fontsize=16)\n",
    "# plt.tight_layout(rect=[0, 0, 0.88, 1])\n",
    "plt.savefig('deepwalk-tsne.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For RandNE MATLAB Adj:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "randne_tsne = tsne.fit_transform(emb_randne_adj_200k_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k', 'lightpink', 'orange', 'purple']\n",
    "for label in range(K_label):\n",
    "    if label in filtered_domains:\n",
    "        continue\n",
    "    candidates = [i for i in range(N) if cols[i] == label]\n",
    "    plt.scatter(randne_tsne[candidates, 0], randne_tsne[candidates, 1],\n",
    "                s=40, c=colors[label], label=top_labels_with_dot[label])\n",
    "plt.legend()\n",
    "# plt.legend(bbox_to_anchor=(1., 0., 1., 1.), loc=1,\n",
    "#            ncol=1, mode=\"expand\", borderaxespad=0., fontsize=16)\n",
    "# plt.tight_layout(rect=[0, 0, 0.88, 1])\n",
    "plt.savefig('randne-tsne.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For RandNE Python Adj:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "randne_py_adj_tsne = tsne.fit_transform(emb_randne_py_adj_200k_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k', 'lightpink', 'orange', 'purple']\n",
    "for label in range(K_label):\n",
    "    if label in filtered_domains:\n",
    "        continue\n",
    "    candidates = [i for i in range(N) if cols[i] == label]\n",
    "    plt.scatter(randne_py_adj_tsne[candidates, 0], randne_py_adj_tsne[candidates, 1],\n",
    "                s=40, c=colors[label], label=top_labels_with_dot[label])\n",
    "plt.legend()\n",
    "plt.savefig('randne-adj-tsne.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For RandNE Python Trans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "randne_py_trans_tsne = tsne.fit_transform(emb_randne_py_trans_200k_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k', 'lightpink', 'orange', 'purple']\n",
    "for label in range(K_label):\n",
    "    if label in filtered_domains:\n",
    "        continue\n",
    "    candidates = [i for i in range(N) if cols[i] == label]\n",
    "    plt.scatter(randne_py_trans_tsne[candidates, 0], randne_py_trans_tsne[candidates, 1],\n",
    "                s=40, c=colors[label], label=top_labels_with_dot[label])\n",
    "plt.legend()\n",
    "plt.savefig('randne-trans-tsne.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search on RandNE Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing to consider is grid searching for better RandNE weights: how does this affect the visualization result?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
